basically we are taking a cnn 
Convolutional neural network 
basically it cuts each image in alot of subset portions
like crops it in many many pieces and then it tried to learn teh curves
shapes and all to differenciate each one 
for now we will train it such that it can take this can store the 
features in a high dimensional space such as 128 dimentions
like each feature has a coordinate in all the 128 axis of 
128 dimension , then it learns to optimise it 
by running tripple loss function

it takes the dataset and learn the ability to put faces in a 128D vector embedding
and then it learned to do it better than better and puts face in the right 
places in the embedding , more close a face is 
more close the embedding position vector of that image will be'

then applying loss it does it better when loss is minimised 
then we just take a vector search method to search a new face 
from that embedding 

type of dataset we need to train :



model working :

face detector model -> crop and cut just the face 


face recog training :
dir 1 : person 1 : img1 , img 2 , dir2 : person 2 : img 1 , img 2 , img 3


The CNN learns to map an input face to a vector embedding 
(for example, 128-dim).
The actual database of embeddings is stored separately — 
e.g., in a file or memory.
During inference, the model generates the embedding for a 
new face,
 and then you compare it to embeddings in your database 
 (using cosine similarity or Euclidean distance) to identify/match
  the face.


...
https://www.kaggle.com/datasets/stoicstatic/face-recognition-dataset

Nikit Periwal · Updated 4 years ago

About Dataset
Welcome to Face Recognition Dataset, a database of face photographs designed for the creation of face detection and recognition models. This dataset has been derived from the Labeled Faces in the Wild Dataset.
This dataset is a collection of JPEG pictures of famous people collected on the internet. All details are available on the official website:
http://vis-www.cs.umass.edu/lfw/

The Dataset
Each picture is centered on a single face, and every image is encoded in RGB. The original images are of the size 250 x 250.
The dataset contains 1680 directories, each representing a celebrity.
Each directory has 2-50 images for the celebrity.
Extracted Faces
Faces extracted from the original image using Haar-Cascade Classifier (cv2)
encoded in RGB and size of image is 128, 128
Acknowledgement
We wouldn't be here without the help of others.
I would like to thank Computer Vision Laboratory, University of Massachusetts for providing us with such an excellent database.

Inspiration
I wanted to build a one-shot model for face recognition. This was the dataset I ended up using for my work. I'm tweaking it and posting it here in Kaggle, so that others can easily use this dataset to build similar models


license: 

CC0 1.0 Universal 
CC0 1.0 Deed

No Copyright
The person who associated a work with this deed has dedicated the work to the public domain by waiving all of his or her rights to the work worldwide under copyright law, including all related and neighboring rights, to the extent allowed by law.
You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. See Other Information below.

Other Information
In no way are the patent or trademark rights of any person affected by CC0, nor are the rights that other persons may have in the work or in how the work is used, such as publicity or privacy rights.
Unless expressly stated otherwise, the person who associated a work with this deed makes no warranties about the work, and disclaims liability for all uses of the work, to the fullest extent permitted by applicable law.
When using or citing the work, you should not imply endorsement by the author or the affirmer.

Your model (the embedding_model) has learned how to map any face image into a vector in embedding space. It doesn’t store identities itself, it just knows how to produce embeddings.

Your embeddings file (embeddings.npz) is what contains the “database” of faces you currently know. Each embedding corresponds to one face image and the associated label (person ID).

